---
title: "The World Is Outsourcing Its Brain to Machines (And We're All Pretending It's Fine)"
date: 2025-11-21
author: "Kadin DeMarche"
tags: ["AI", "technology", "society", "dependence"]
excerpt: "We outsourced memory to smartphones. Now we're outsourcing thinking to AI. At what point did we agree this was a good idea?"
---

# The World Is Outsourcing Its Brain to Machines (And We're All Pretending It's Fine)

I haven't memorized a phone number since I got a phone (excluding my parents since that was a requirment for me to get a phone).

Why would I? My phone knows everyone's number. It knows their address, their birthday, their email, their social media handles. My brain doesn't need to store that information anymore.

This seemed fine until I realized: I've also stopped memorizing directions, facts, math, spelling, and increasingly, how to think through types of problems.

We're not just using AI as a tool. We're using it as a replacement for cognitive effort.

## The Progression of Outsourcing

**1990s: We outsourced calculation**

Calculators became standard. Mental math skills declined. Teachers complained. Society decided this was fine because calculators are just tools.

**2000s: We outsourced memory**

Smartphones became ubiquitous. Nobody memorizes phone numbers, addresses, or directions anymore. Why would you? That information is always available.

**2010s: We outsourced navigation**

GPS killed map reading. I literally cannot navigate without Google Maps. If my phone dies in an unfamiliar city, I'm lost. Not "I'll figure it out" lost—actually, genuinely lost.

**2020s: We're outsourcing thinking**

ChatGPT writes essays. Copilot writes code. AI summarizes articles, analyzes data, makes recommendations. We're starting to outsource the actual process of reasoning.

**At what point does "tool" become "dependency"?**

## The Difference Between Tools and Replacements

A hammer is a tool. It makes hitting nails easier. But if you lose the hammer, you can still hit a nail with a rock. The skill isn't lost.

**GPS isn't a tool. It's a replacement.**

I never learned how to read a map properly because GPS existed. The skill was never developed. If GPS disappeared tomorrow, I couldn't navigate. The ability is gone.

**And I'm pissed about it.**

**AI is becoming a replacement, not a tool.**

Students aren't using ChatGPT to check their essays. They're using it to write the essays, then editing slightly. The skill of constructing an argument from scratch? Never developed.

Developers aren't using Copilot to speed up coding. They're using it to generate code they don't fully understand, then debugging when it breaks. The skill of thinking through logic from first principles? Atrophying (can I get extra credit for using a big word Ms. Rode?).

And everyone acts like this is progress.

## We're Getting Cognitively Lazy (And It's Rational)

Here's the uncomfortable truth: outsourcing thinking makes sense in the moment.

**Why people use AI instead of thinking:**

- It's faster (ChatGPT writes in seconds what takes humans minutes)
- It's often better (AI grammar and structure beat most people's first drafts)
- It's always available (no mental fatigue, no motivation issues)
- It's free cognitive capacity (save your brain for harder problems, supposedly)

This is completely logical behavior. If a machine does something better and faster, why wouldn't you use it?

**But here's what society is trading away:**

- The ability to think deeply when AI isn't available
- Pattern recognition from doing things the hard way
- Understanding that comes from struggle
- Intellectual independence
- The satisfaction of actually creating something yourself

We're making a deal: give up cognitive development in exchange for immediate efficiency.

Short term, it's a great trade. Long term? We're definitely screwed.

**And the worst part? You can't opt out.** If everyone else uses AI and you don't, you fall behind. It's a race to cognitive dependence, and abstaining means losing.

## The "Surely We'll Still Learn the Basics" Cope

People say: "Don't worry, students will still learn fundamentals before using AI."

Will they?

**Nobody learns map reading before using GPS.**

When I got my license, driver's ed didn't teach map reading. Why would it? GPS exists. Teaching obsolete skills is a waste of time.

**Nobody learns mental math before using calculators.**

Sure, elementary school teaches arithmetic. But higher math assumes calculator access. Nobody's doing integrals by hand when computers exist.

**Why would anyone learn writing before using ChatGPT?**

If AI can write better than most humans, why spend years teaching essay structure? Just teach "how to prompt AI effectively" and move on.

This sounds dystopian. It's also the logical endpoint of educational efficiency.

Why teach skills that machines do better?

## The "AI Is Just a Tool" Cope

Every time this comes up, someone says: "AI is just a tool, like a calculator. We still need to know what to do with it."

This is technically true and practically misleading.

**Calculators required understanding:**

- You need to know which calculation to perform
- You need to interpret the result
- You need to verify it makes sense
- The calculator doesn't think for you

**ChatGPT requires way less understanding:**

- Just describe what you want in plain English
- AI figures out the approach
- AI generates the output
- You just accept or reject it

The cognitive load is massively different.

Using a calculator: "I need to divide 847 by 23. Calculator says 36.8. That seems right."

Using ChatGPT: "Write me an analysis of the impacts of social media." _AI outputs 5 paragraphs_ "Sure, that sounds smart."

One requires understanding. The other requires reading comprehension.

## We're Creating a Two-Tier Society

There's a split emerging:

**Tier 1: People who understand AI**

- Know how it works (training data, weights, transformers)
- Know its limitations (hallucinations, biases, context windows)
- Use AI as an extension of their thinking
- Could function without AI if necessary

**Tier 2: People who depend on AI**

- Know it "just works" somehow
- Don't understand limitations or failure modes
- Use AI as a replacement for thinking
- Would be helpless without AI

The scary part? Tier 2 will include most people. Including people in important positions.

**Future scenario:**

- CEO asks AI to analyze market trends
- AI generates report with confident but flawed reasoning
- CEO doesn't understand the domain well enough to spot the error
- Company makes multimillion-dollar decision based on AI hallucination

We're replacing human expertise with AI confidence. Those aren't the same thing.

## What Happens When AI Goes Down?

Our society has critical dependencies:

**Power grid:** If it fails, we have generators and backup systems
**Internet:** If it fails, we have offline backups and manual processes
**AI:** If it fails, we... have no plan because we assume it won't fail

But AI can fail:

- Servers go down (happens regularly)
- Models get worse (happened with GPT-4 degradation)
- Companies shut down services (RIP Google products)
- Cyberattacks or sabotage

**What happens if ChatGPT goes offline for a week?**

- Students can't finish assignments (because they don't know how to write)
- Developers can't meet deadlines (because they can't code without Copilot)
- Customer service collapses (because chatbots handle 80% of queries now, looking at you Capital One...)
- Productivity craters across industries

The scary thing? This isn't even a stretch. We're maybe 2-3 years from this level of dependency.

## The Cognitive Atrophy Problem

Use it or lose it isn't just a saying. It's neuroscience.

**Skills our generation has lost to technology:**

- Spelling (spell check catches everything)
- Mental math (calculators are always available)
- Remembering facts (Google knows everything)
- Navigation (GPS handles it)
- Handwriting, specifically cursive (everyone types now)

For people who grew up with technology, these skills never developed properly in the first place.

**What happens when the next generation loses:**

- The ability to write without AI assistance
- The ability to code without AI autocomplete
- The ability to analyze problems without AI prompts
- The ability to think deeply without external tools

Society becomes cognitively dependent. Like someone who skips leg day for years, then can't walk without assistance.

## The Counterargument: "Every Generation Says This"

Socrates complained that writing would destroy memory. People said calculators would make us dumb. The internet was supposed to rot our brains.

We adapted. We're fine.

**Why this time might be different:**

**Writing:** Outsourced information storage, not thinking
**Calculators:** Outsourced computation, not reasoning
**Internet:** Outsourced information retrieval, not understanding
**AI:** Outsources thinking itself

Each step moved higher up the cognitive stack.

Memory → calculation → information access → reasoning

We're running out of cognitive layers to outsource.

What's left after we automate thinking?

## Are We Okay With This?

Honest question: do we want a world where humans don't need to think?

**The Silicon Valley pitch:**

- Focus on creativity and innovation instead of routine, boring work
- More free time for relationships and experiences
- Access to expertise for everyone
- Faster progress on hard problems

**The actual reality:**

- Loss of intellectual independence
- Society-wide cognitive decline
- Extreme vulnerability to technology failure
- Concentration of power in who controls the AI
- Humans reduced to clicking "regenerate" until AI outputs something acceptable

This isn't like the transition from physical labor to knowledge work. That gave us new jobs. This is different.

Machines took over manual tasks, humans moved to cognitive tasks. Now AI takes over cognitive tasks, humans move to... what exactly?

**Creative work?** AI generates art and music better than most people.
**Strategic thinking?** AI does analysis and planning faster than we do.
**Emotional labor?** AI chatbots provide therapy and companionship without judgment.

What's left? Consuming? Is that the endpoint—humans as passive consumers of AI-generated everything?

**That's bleak. And nobody's talking about it.**

## The Resistance Is Futile (But Necessary)

Some people still try to think without AI.

They'll write first drafts without ChatGPT. Code functions without Copilot. Solve problems manually before asking AI.

Not because it's faster. It's not. Not because it's better. It usually isn't.

Because they don't want to become helpless when the machine is unavailable.

**Is this the equivalent of insisting on using a typewriter in 2025?**

Probably.

But there's something fundamentally wrong about outsourcing your brain to a corporation's servers. We're trading independence for convenience, and acting like it's an upgrade.

**This is a bad deal. But it's also the only deal available.**

The people who resist get left behind. The people who adopt it lose their cognitive independence. There's no winning move, just choosing which way you want to lose.

## The Uncomfortable Endpoint

We're moving toward a world where AI does most cognitive work and humans... oversee it? Enjoy the output? Become obsolete?

**The optimistic view:** humans are freed from tedious thinking to focus on meaning, creativity, and connection.

**The pessimistic view:** humans become intellectually dependent, cognitively atrophied, and unable to function without AI assistance.

**The realistic view:** The pessimistic scenario is already happening. We're not heading toward cognitive dependence—we're already there. And it's accelerating.

Some people will use AI as a tool to amplify their thinking. Most people will use AI as a replacement for thinking. The gap between those groups will become a chasm, and the people who control the AI will control everyone else.

**This isn't progress. It's a gamble.**

Society is betting that AI companies will act in our best interests, that the technology won't be weaponized, that we'll somehow adapt before we lose the ability to think independently.

That's a bad bet.

---

_Outsourcing our thinking is a tragedy. But it's probably unstoppable._

_The momentum is too strong, the incentives too powerful, the convenience too seductive. Dark side is calling, do they have cookies?_

_We're building our own obsolescence, and calling it innovation. I feel like we are in a Sci-Fi film._

_And the worst part? The people warning about it will be the ones left behind._
